{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AEPntm2K7YOv"
   },
   "outputs": [],
   "source": [
    "# Import PyDrive and associated libraries.\n",
    "# This only needs to be done once per notebook.\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once per notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Download a file based on its file ID.\n",
    "#\n",
    "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
    "file_id = '1Tvi4Vk8MIBsVi4MIHX1zoDe6UsKpWBqj'\n",
    "downloaded = drive.CreateFile({'id': file_id})\n",
    "downloaded.GetContentFile('captcha.zip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BkwCmmycE5Qu"
   },
   "outputs": [],
   "source": [
    "!unzip captcha.zip > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0Q03BYxDawz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def make_dirs():\n",
    "  data_root = 'captcha'\n",
    "  train_dir = 'train'\n",
    "  val_dir = 'val'\n",
    "  test_dir = 'test'\n",
    "  classes =  ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "  for dir_name in [train_dir, val_dir, test_dir]:\n",
    "      for class_name in classes:\n",
    "          os.makedirs(os.path.join(dir_name, class_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Vqx79EDslN1"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "def divide_data():\n",
    "  j = 0\n",
    "  train_indexes = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "  test_indexes = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "  val_indexes = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "  for filename in glob.glob('captcha/*.png'): \n",
    "      im=Image.open(filename)\n",
    "      begining = 5;\n",
    "      end = 30;\n",
    "      width = 15;\n",
    "      for i in range(5):\n",
    "          im_cropped = im.crop((begining+i*width, 0, end+i*width, 48))\n",
    "          if j%2 == 0:\n",
    "            im_cropped.save(os.path.join('test', filename[-9+i])+'/' + filename[-9+i]+'_'+ str(test_indexes[int(filename[-9+i])]) + '.png', format = 'png')\n",
    "            test_indexes[int(filename[-9+i])] = test_indexes[int(filename[-9+i])] + 1\n",
    "          elif j%7 == 0:\n",
    "            im_cropped.save(os.path.join('val', filename[-9+i])+'/' + filename[-9+i]+'_'+ str(val_indexes[int(filename[-9+i])]) + '.png', format = 'png')\n",
    "            val_indexes[int(filename[-9+i])] = val_indexes[int(filename[-9+i])] + 1\n",
    "          else:\n",
    "            im_cropped.save(os.path.join('train', filename[-9+i])+'/' + filename[-9+i]+'_'+ str(train_indexes[int(filename[-9+i])]) + '.png', format = 'png')\n",
    "            train_indexes[int(filename[-9+i])] = train_indexes[int(filename[-9+i])] + 1\n",
    "      j = j+1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dirs()\n",
    "divide_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZW8fv0Q_WUsR"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.determenistic = True\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder('train', torchvision.transforms.ToTensor())\n",
    "val_dataset = torchvision.datasets.ImageFolder('val', torchvision.transforms.ToTensor())\n",
    "batch_size = 10;\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers= batch_size)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers= batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aBjAW-y5azJy"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_tensorImage(tensorImage, title = ''):\n",
    "    image = tensorImage.permute(1, 2, 0).numpy()\n",
    "    plt.imshow(image.clip(0, 1))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BBeWI4k26tyW",
    "outputId": "8c746da7-0c9c-4e34-888b-7692e1c5ee3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m0\u001b[0m/  \u001b[01;34m1\u001b[0m/  \u001b[01;34m2\u001b[0m/  \u001b[01;34m3\u001b[0m/  \u001b[01;34m4\u001b[0m/  \u001b[01;34m5\u001b[0m/  \u001b[01;34m6\u001b[0m/  \u001b[01;34m7\u001b[0m/  \u001b[01;34m8\u001b[0m/  \u001b[01;34m9\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-hCYDyAr6oT6",
    "outputId": "63d25ee7-3e49-492d-9fd8-674369189332"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214285"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uY-vyOXjaQ_P"
   },
   "outputs": [],
   "source": [
    "inputs, labels = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YY8UEoXF-1BO",
    "outputId": "24616928-5dbe-4187-a725-13388e44bd4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 48, 25])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vbHTT8SB9gl6"
   },
   "outputs": [],
   "source": [
    "class CaptchaNet(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CaptchaNet, self).__init__()\n",
    "    self.conv1 = torch.nn.Conv2d(in_channels = 3, out_channels = 3,\n",
    "                                kernel_size = 3, padding = 1) # size = 48*25\n",
    "    self.conv2 = torch.nn.Conv2d(in_channels = 3, out_channels = 6,\n",
    "                                kernel_size = 3, padding = 1) # size = 48*25\n",
    "    self.act1 = torch.nn.ReLU()\n",
    "    self.norm1 = torch.nn.BatchNorm2d(num_features = 6)\n",
    "    self.pool1 = torch.nn.MaxPool2d(kernel_size = 2, stride = 2) # size = 24*12\n",
    "    \n",
    "    self.conv3 = torch.nn.Conv2d(in_channels = 6, out_channels = 11, \n",
    "                                 kernel_size = 3, padding = 0) # size = 22*10\n",
    "    self.conv4 = torch.nn.Conv2d(in_channels = 11, out_channels = 16,\n",
    "                                kernel_size = 3, padding = 0) # size = 20*8\n",
    "    self.act2 = torch.nn.ReLU()\n",
    "    self.norm1 = torch.nn.BatchNorm2d(num_features = 16)\n",
    "    self.pool2 = torch.nn.MaxPool2d(kernel_size = 2, stride = 2) # size = 10*4\n",
    "    \n",
    "    self.fc1 = torch.nn.Linear(10*4*16, 120)\n",
    "    self.act3 = torch.nn.ReLU()\n",
    "    self.fc2 = torch.nn.Linear(120, 84)\n",
    "    self.act4 = torch.nn.ReLU()\n",
    "    self.fc3 = torch.nn.Linear(84, 10)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.act1(x)\n",
    "    x = self.pool1(x)\n",
    "    \n",
    "    x = self.conv3(x)\n",
    "    x = self.conv4(x)\n",
    "    x = self.act2(x)\n",
    "    x = self.pool2(x)\n",
    "    \n",
    "    x = x.view(x.size(0), x.size(1)* x.size(2)* x.size(3))\n",
    "    x = self.fc1(x)\n",
    "    x = self.act3(x)\n",
    "    x = self.fc2(x)\n",
    "    x = self.act4(x)\n",
    "    x = self.fc3(x)\n",
    "    \n",
    "    return x\n",
    "  \n",
    "\n",
    "model = CaptchaNet() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fojw9yUOBWFq"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhki--pwAtoh"
   },
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss();\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3, amsgrad=True, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ToTOfy8oCdxd"
   },
   "outputs": [],
   "source": [
    "def train_model(num_epochs):\n",
    "  train_loss_history = []\n",
    "  val_loss_history = []\n",
    "  train_accuracy_history = []\n",
    "  val_accuracy_history = []\n",
    "  for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n",
    "    for phase in ['train', 'val']:\n",
    "      if phase == 'train':\n",
    "        dataloader = train_dataloader\n",
    "        model.train()\n",
    "      else:\n",
    "        dataloader = val_dataloader\n",
    "        model.eval()\n",
    "      running_loss = 0\n",
    "      running_acc = 0\n",
    "      for x_batch, y_batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        preds = model.forward(x_batch)\n",
    "        loss_value = loss(preds, y_batch)\n",
    "        preds_classes = preds.argmax(dim=1)\n",
    "        if phase == 'train':\n",
    "          loss_value.backward()\n",
    "          optimizer.step()\n",
    "        running_loss += loss_value.item()\n",
    "        running_acc += (preds_classes == y_batch.data).float().mean()\n",
    "    \n",
    "      epoch_loss = running_loss / len(dataloader)\n",
    "      epoch_acc = running_acc / len(dataloader)\n",
    "      if (phase == 'train'):\n",
    "        train_accuracy_history.append(epoch_acc.data.cpu())\n",
    "        train_loss_history.append(epoch_loss) \n",
    "      else:\n",
    "        val_accuracy_history.append(epoch_acc.data.cpu())\n",
    "        val_loss_history.append(epoch_loss) \n",
    "      print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), flush=True)\n",
    "    scheduler.step()\n",
    "  plt.figure(1)\n",
    "  plt.title('train_accuracy')\n",
    "  plt.plot(train_accuracy_history)\n",
    "  \n",
    "  plt.figure(2)\n",
    "  plt.title('val_accuracy')\n",
    "  plt.plot(val_accuracy_history)  \n",
    "  plt.figure(3)\n",
    "  plt.title('train loss')\n",
    "  plt.plot(train_loss_history, 'r')\n",
    "  \n",
    "  plt.figure(4)\n",
    "  plt.title('val loss')\n",
    "  plt.plot(val_loss_history, 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6AfdTCzHKPTT"
   },
   "outputs": [],
   "source": [
    "test_folder = torchvision.datasets.ImageFolder('test',torchvision.transforms.ToTensor())\n",
    "test_dataloader = torch.utils.data.DataLoader(test_folder,batch_size = batch_size, num_workers=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KIs06lxHPz_A"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "accuracy = 0\n",
    "for x_batch, y_batch in test_dataloader:\n",
    "  x_batch = x_batch.to(device)\n",
    "  y_batch = y_batch.to(device)\n",
    "  preds = model.forward(x_batch)\n",
    "  preds_classes = preds.argmax(dim=1)\n",
    "  accuracy += (y_batch == preds_classes).float().mean()\n",
    "accuracy = accuracy/len(test_dataloader)\n",
    "print(accuracy)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YVBrMFbNnM8F"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'params.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9U03ePRoEcn"
   },
   "outputs": [],
   "source": [
    "# Import PyDrive and associated libraries.\n",
    "# This only needs to be done once in a notebook.\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once in a notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Create & upload a text file.\n",
    "uploaded = drive.CreateFile({'title': 'params.txt'})\n",
    "uploaded.SetContentFile('params.txt')\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Captcha.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
